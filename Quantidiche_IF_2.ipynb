{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gretarobur/pyqb-20220714/blob/main/Quantidiche_IF_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNnS793rldr8",
        "outputId": "5b790b2e-bb04-4091-8781-2e2dd7ac8a44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting xlsxwriter\n",
            "  Downloading XlsxWriter-3.1.9-py3-none-any.whl (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xlsxwriter\n",
            "Successfully installed xlsxwriter-3.1.9\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from collections import Counter\n",
        "!pip install xlsxwriter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qPN41be-hwwE"
      },
      "outputs": [],
      "source": [
        "#@title !!! Voxel Size: Inserire la dimensione dei pixel in X/Y e Z (Info dell'immagine) !!!\n",
        "XY_pixel = 0.0964 #@param {type:\"raw\"}\n",
        "Z_pixel = 0.4196 #@param {type:\"raw\"}\n",
        "\n",
        "voxel_size = XY_pixel * XY_pixel * Z_pixel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g7zv2Bk20E-k"
      },
      "outputs": [],
      "source": [
        "#@title !!! Scrivere il canale che si vuole quantificare (KAP1/HP1/BRD4) !!!\n",
        "Canale = \"SUZ12\" #@param {type:\"string\"}\n",
        "if Canale == \"KAP1\":\n",
        "  Canale = 1\n",
        "elif Canale == \"HP1\" or \"BRD4\" or \"SUZ12\":\n",
        "  Canale = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTMgMJWFljS9",
        "outputId": "ab6bec88-0a45-4d49-b695-9764ff82c4c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZDrMJi-allCm"
      },
      "outputs": [],
      "source": [
        "directory = \"/content/drive/MyDrive/Analysis\"\n",
        "files = os.listdir(directory)\n",
        "\n",
        "fields = []\n",
        "for subfolder in files:\n",
        "  fields.append(subfolder)\n",
        "\n",
        "directory_analysis = []\n",
        "for subfolder in files:\n",
        "  directory_analysis.append(directory + \"/\" + subfolder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XaxpzXSbhEFb",
        "outputId": "b9a90b51-1c06-4e29-900c-addf6be4d5b9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['M_5122_eff_tex_kap_suz12 - Mark_and_Find_001-Pos005_S001.tif.csv',\n",
              " 'Q_5122_eff_tex_kap_suz12 - Mark_and_Find_001-Pos005_S001.tif KAP1.csv',\n",
              " 'Q_5122_eff_tex_kap_suz12 - Mark_and_Find_001-Pos005_S001.tif SUZ12.csv',\n",
              " 'serie_05.csv']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "alist = os.listdir(directory_analysis[0])\n",
        "\n",
        "alist.sort()\n",
        "alist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cCOMTARRlpd3"
      },
      "outputs": [],
      "source": [
        "field = []\n",
        "for subfolder in directory_analysis:\n",
        "  field.append(subfolder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vGCLGg6zmRMN"
      },
      "outputs": [],
      "source": [
        "def la_distanza(il_pallino, il_nucleo):\n",
        "  return math.sqrt((il_nucleo[0] - il_pallino[0])**2 + (il_nucleo[1] - il_pallino[1])**2)\n",
        "\n",
        "def distance_3D(il_pallino, nuclei_data):\n",
        "  return math.sqrt((nuclei_data[1] - il_pallino[0])**2 + (nuclei_data[2] - il_pallino[1])**2 + (nuclei_data[3] - il_pallino[2])**2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p7gFgVNuvTpr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d14069e9-42c0-4341-f8a7-d7f8fa86fea3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Analysis/Serie5\n",
            "/content/drive/MyDrive/Analysis/Serie5/Serie5.xlsx\n",
            "['M_5122_eff_tex_kap_suz12 - Mark_and_Find_001-Pos005_S001.tif.csv', 'Q_5122_eff_tex_kap_suz12 - Mark_and_Find_001-Pos005_S001.tif KAP1.csv', 'Q_5122_eff_tex_kap_suz12 - Mark_and_Find_001-Pos005_S001.tif SUZ12.csv', 'serie_05.csv']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-d98922fb08af>:113: FutureWarning: save is not part of the public API, usage can give unexpected results and will be removed in a future version\n",
            "  xlsx_file.save()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Analysis/Serie3\n",
            "/content/drive/MyDrive/Analysis/Serie3/Serie3.xlsx\n",
            "['M_5122_eff_tex_kap_suz12 - Mark_and_Find_001-Pos003_S001.tif.csv', 'Q_5122_eff_tex_kap_suz12 - Mark_and_Find_001-Pos003_S001.tif KAP1.csv', 'Q_5122_eff_tex_kap_suz12 - Mark_and_Find_001-Pos003_S001.tif SUZ12.csv', 'serie_03.csv']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-d98922fb08af>:113: FutureWarning: save is not part of the public API, usage can give unexpected results and will be removed in a future version\n",
            "  xlsx_file.save()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Analysis/Serie6_ex\n",
            "/content/drive/MyDrive/Analysis/Serie6_ex/Serie6_ex.xlsx\n",
            "['M_5122_eff_tex_kap_suz12 - Mark_and_Find_001-Pos006_S001 tex.tif.csv', 'Q_5122_eff_tex_kap_suz12 - Mark_and_Find_001-Pos006_S001 tex.tif KAP1.csv', 'Q_5122_eff_tex_kap_suz12 - Mark_and_Find_001-Pos006_S001 tex.tif SUZ12.csv', 'serie_06.csv']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-d98922fb08af>:113: FutureWarning: save is not part of the public API, usage can give unexpected results and will be removed in a future version\n",
            "  xlsx_file.save()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Analysis/Serie9\n",
            "/content/drive/MyDrive/Analysis/Serie9/Serie9.xlsx\n",
            "['M_5122_eff_tex_kap_suz12 - Mark_and_Find_001-Pos009_S001.tif.csv', 'Q_5122_eff_tex_kap_suz12 - Mark_and_Find_001-Pos009_S001.tif KAP1.csv', 'Q_5122_eff_tex_kap_suz12 - Mark_and_Find_001-Pos009_S001.tif SUZ12.csv', 'serie_09.csv']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-d98922fb08af>:113: FutureWarning: save is not part of the public API, usage can give unexpected results and will be removed in a future version\n",
            "  xlsx_file.save()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Analysis/Serie2\n",
            "/content/drive/MyDrive/Analysis/Serie2/Serie2.xlsx\n",
            "['M_5122_eff_tex_kap_suz12 - Mark_and_Find_001-Pos002_S001.tif.csv', 'Q_5122_eff_tex_kap_suz12 - Mark_and_Find_001-Pos002_S001.tif KAP1.csv', 'Q_5122_eff_tex_kap_suz12 - Mark_and_Find_001-Pos002_S001.tif SUZ12.csv', 'serie_02.csv']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-d98922fb08af>:113: FutureWarning: save is not part of the public API, usage can give unexpected results and will be removed in a future version\n",
            "  xlsx_file.save()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Analysis/Serie10\n",
            "/content/drive/MyDrive/Analysis/Serie10/Serie10.xlsx\n",
            "['M_5122_eff_tex_kap_suz12 - Mark_and_Find_001-Pos010_S001.tif.csv', 'Q_5122_eff_tex_kap_suz12 - Mark_and_Find_001-Pos010_S001.tif KAP1.csv', 'Q_5122_eff_tex_kap_suz12 - Mark_and_Find_001-Pos010_S001.tif SUZ12.csv', 'serie_10.csv']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-d98922fb08af>:113: FutureWarning: save is not part of the public API, usage can give unexpected results and will be removed in a future version\n",
            "  xlsx_file.save()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Analysis/Serie1_eff\n",
            "/content/drive/MyDrive/Analysis/Serie1_eff/Serie1_eff.xlsx\n",
            "['M_5122_eff_tex_kap_suz12 - Mark_and_Find_001-Pos001_S001 eff.tif.csv', 'Q_5122_eff_tex_kap_suz12 - Mark_and_Find_001-Pos001_S001 eff.tif KAP1.csv', 'Q_5122_eff_tex_kap_suz12 - Mark_and_Find_001-Pos001_S001 eff.tif SUZ12.csv', 'serie_01.csv']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-d98922fb08af>:113: FutureWarning: save is not part of the public API, usage can give unexpected results and will be removed in a future version\n",
            "  xlsx_file.save()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Analysis/Serie4\n",
            "/content/drive/MyDrive/Analysis/Serie4/Serie4.xlsx\n",
            "['M_5122_eff_tex_kap_suz12 - Mark_and_Find_001-Pos004_S001.tif.csv', 'Q_5122_eff_tex_kap_suz12 - Mark_and_Find_001-Pos004_S001.tif KAP1.csv', 'Q_5122_eff_tex_kap_suz12 - Mark_and_Find_001-Pos004_S001.tif SUZ12.csv', 'serie_04.csv']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-d98922fb08af>:113: FutureWarning: save is not part of the public API, usage can give unexpected results and will be removed in a future version\n",
            "  xlsx_file.save()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Analysis/Serie8\n",
            "/content/drive/MyDrive/Analysis/Serie8/Serie8.xlsx\n",
            "['M_5122_eff_tex_kap_suz12 - Mark_and_Find_001-Pos008_S001.tif.csv', 'Q_5122_eff_tex_kap_suz12 - Mark_and_Find_001-Pos008_S001.tif KAP1.csv', 'Q_5122_eff_tex_kap_suz12 - Mark_and_Find_001-Pos008_S001.tif SUZ12.csv', 'serie_08.csv']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-d98922fb08af>:113: FutureWarning: save is not part of the public API, usage can give unexpected results and will be removed in a future version\n",
            "  xlsx_file.save()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Analysis/Serie7\n",
            "/content/drive/MyDrive/Analysis/Serie7/Serie7.xlsx\n",
            "['M_5122_eff_tex_kap_suz12 - Mark_and_Find_001-Pos007_S001.tif.csv', 'Q_5122_eff_tex_kap_suz12 - Mark_and_Find_001-Pos007_S001.tif KAP1.csv', 'Q_5122_eff_tex_kap_suz12 - Mark_and_Find_001-Pos007_S001.tif SUZ12.csv', 'serie_07.csv']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-d98922fb08af>:113: FutureWarning: save is not part of the public API, usage can give unexpected results and will be removed in a future version\n",
            "  xlsx_file.save()\n"
          ]
        }
      ],
      "source": [
        "list_merged = []\n",
        "dict_merged = {}\n",
        "for experiment in directory_analysis:\n",
        "\n",
        "  # Lista dei centroidi dei nuclei\n",
        "  # Tutte le distanze/volumi sono in pixel/voxel, sono da moltiplicare per la dimensione reale\n",
        "  # Nuclei = [(X_centroid, Y_centroid, Z_centroid, X_max, X_min, Y_max, Y_min, Z_max, Z_min, volume)]\n",
        "  #nuclei = [(\"N_nuclei\", \"x_c_nuclei\", \"y_c_nuclei\", \"z_c_nuclei\", \"volume_nuclei\", \"X_max\", \"X_min\", \"Y_max\", \"Y_min\", \"Z_max\", \"Z_min\")]\n",
        "\n",
        "\n",
        "  csv = os.listdir(experiment)\n",
        "  file_path = experiment + \"/\" + csv[1]\n",
        "  csv.sort()\n",
        "  print(experiment)\n",
        "  xlsx_file_path = experiment + \"/\" + experiment.split(\"/\")[-1] + \".xlsx\"\n",
        "  print(xlsx_file_path)\n",
        "  xlsx_file = pd.ExcelWriter(xlsx_file_path, engine='xlsxwriter')\n",
        "\n",
        "  print(csv)\n",
        "\n",
        "  nome_file_nuclei = experiment + \"/\" + csv[0]\n",
        "  nome_file_droplet = experiment + \"/\" + csv[3]\n",
        "  nome_file_quantifiche_nucleo_canale = experiment + \"/\" + csv[Canale]\n",
        "\n",
        "  nuclei_data = []\n",
        "\n",
        "  N_nuclei = pd.read_csv(nome_file_nuclei)['Nb'].tolist()\n",
        "  x_c_nuclei = pd.read_csv(nome_file_nuclei)['CX (unit)'].tolist()\n",
        "  y_c_nuclei = pd.read_csv(nome_file_nuclei)['CY (unit)'].tolist()\n",
        "  z_c_nuclei = pd.read_csv(nome_file_nuclei)['CZ (unit)'].tolist()\n",
        "  volume_nuclei = pd.read_csv(nome_file_nuclei)['Vol (unit)'].tolist()\n",
        "\n",
        "  N_nuclei_canale = pd.read_csv(nome_file_quantifiche_nucleo_canale)['Nb'].tolist()\n",
        "  MFI = pd.read_csv(nome_file_quantifiche_nucleo_canale)['Mean'].tolist()\n",
        "\n",
        "  channel_data = [(N_nuclei_canale[i], MFI[i]) for i in range(0, len(x_c_nuclei))]\n",
        "\n",
        "  #X_max = pd.read_csv(nome_file_nuclei)['Xmax (pix)'].tolist()\n",
        "  #X_min = pd.read_csv(nome_file_nuclei)['Xmin (pix)'].tolist()\n",
        "  #Y_max = pd.read_csv(nome_file_nuclei)['Ymax (pix)'].tolist()\n",
        "  #Y_min = pd.read_csv(nome_file_nuclei)['Ymin (pix)'].tolist()\n",
        "  #Z_max = pd.read_csv(nome_file_nuclei)['Zmax (pix)'].tolist()\n",
        "  #Z_min = pd.read_csv(nome_file_nuclei)['Zmin (pix)'].tolist()\n",
        "\n",
        "  #nuclei_data = [(N_nuclei[i], x_c_nuclei[i], y_c_nuclei[i], z_c_nuclei[i], volume_nuclei[i], X_max[i], X_min[i], Y_max[i], Y_min[i], Z_max[i], Z_min[i]) for i in range(0, len(x_c_nuclei))]\n",
        "  nuclei_data = [(N_nuclei[i], x_c_nuclei[i], y_c_nuclei[i], z_c_nuclei[i], volume_nuclei[i]) for i in range(0, len(x_c_nuclei))]\n",
        "\n",
        "  # Droplet = [(x_c_droplet, y_c_droplet, z_c_droplet, droplet_fluorescence droplet_volume, nucleo associato, x del nucleo, y del nucleo, distanza dal centroide)]\n",
        "\n",
        "  x_c_droplet_pix = pd.read_csv(nome_file_droplet)['X'].tolist()\n",
        "  x_c_droplet = [i * XY_pixel for i in x_c_droplet_pix]\n",
        "  y_c_droplet_pix = pd.read_csv(nome_file_droplet)['Y'].tolist()\n",
        "  y_c_droplet = [i * XY_pixel for i in y_c_droplet_pix]\n",
        "  z_c_droplet_pix = pd.read_csv(nome_file_droplet)['Z'].tolist()\n",
        "  z_c_droplet = [i * Z_pixel for i in z_c_droplet_pix]\n",
        "  droplet_volume_vox = pd.read_csv(nome_file_droplet)['Size'].tolist()\n",
        "  droplet_volume = [i * voxel_size for i in droplet_volume_vox]\n",
        "  droplet_fluorescence = pd.read_csv(nome_file_droplet)['Av'].tolist()\n",
        "\n",
        "  #le_aree = pd.read_csv(nome_file_droplet + '.csv')['Size'].tolist()\n",
        "  #le_fluorescenze = pd.read_csv(nome_file_droplet + '.csv')['Av'].tolist()\n",
        "  droplets = [[x_c_droplet[i], y_c_droplet[i], z_c_droplet[i], droplet_volume[i], droplet_fluorescence[i], 0, 0, 0, 0, 0, None, None, 0] for i in range(0, len(x_c_droplet))]\n",
        "  droplets_list = [[x_c_droplet[i], y_c_droplet[i], z_c_droplet[i], droplet_volume[i], droplet_fluorescence[i], 0, 0, 0, 0, 0, None, None, 0] for i in range(0, len(x_c_droplet))]\n",
        "\n",
        "  Nuclei_DF = pd.DataFrame (nuclei_data, columns = [\"Nb\", \"Cx\", \"Cy\",\"Cz\",\"Volume_unit\"])\n",
        "  Nuclei_DF[\"Nb\"] = Nuclei_DF[\"Nb\"] + 1\n",
        "  Nuclei_DF['Channel intensisty'] = pd.read_csv(nome_file_quantifiche_nucleo_canale)['Mean'].tolist()\n",
        "  Nuclei_DF.drop(Nuclei_DF[Nuclei_DF['Volume_unit'] <= 10].index, inplace = True)\n",
        "  Nuclei_DF[\"Volume_pix\"] = Nuclei_DF[\"Volume_unit\"] / voxel_size\n",
        "\n",
        "  if len(Nuclei_DF) == 0:\n",
        "    with open(experiment + '/log.txt', 'w') as f:\n",
        "      f.write('No nuclei')\n",
        "  else:\n",
        "    Droplets_DF = pd.DataFrame (droplets_list, columns = [\"Cx\",\"Cy\",\"Cz\",\"Volume_unit\",\"Fluorescence\",\"Centroid_distance\",\"Nucleus_ID\",\"0\",\"0\",\"0\",\"Nucleo\",\"N_Dots\",\"0\"])\n",
        "\n",
        "    conta_dxn = {}\n",
        "    nuclei_index = []\n",
        "    min_distance = []\n",
        "    Nuclei_index_touse = Nuclei_DF.Nb.tolist()\n",
        "    for i, row_D in Droplets_DF.iterrows():\n",
        "      distances = []\n",
        "      for k, row_N in Nuclei_DF.iterrows():\n",
        "        droplet_distance = distance_3D (row_D,row_N)\n",
        "        distances.append(droplet_distance)\n",
        "      index_min = distances.index(min(distances))\n",
        "      min_distance.append(min(distances))\n",
        "      nuclei_index.append(Nuclei_index_touse[index_min])\n",
        "\n",
        "    Droplets_DF[\"Centroid_distance\"] = min_distance\n",
        "    Droplets_DF[\"Nucleus_ID\"] = nuclei_index\n",
        "    Droplets_DF[\"Nucleus_ID\"] = Droplets_DF[\"Nucleus_ID\"]\n",
        "    Droplets_DF.drop(Droplets_DF[Droplets_DF['Centroid_distance'] >= 20].index, inplace = True)\n",
        "\n",
        "    conta_dxn = Counter(Droplets_DF[\"Nucleus_ID\"])\n",
        "    keys = list(conta_dxn.keys())\n",
        "    keys.sort()\n",
        "    sorted_conta_dxn = {i: conta_dxn[i] for i in keys}\n",
        "\n",
        "    key_list = list(sorted_conta_dxn.keys())\n",
        "    value_list = list(sorted_conta_dxn.values())\n",
        "    Dots_Nucleus = pd.DataFrame(key_list, columns = [\"Nucleo\"])\n",
        "    Dots_Nucleus[\"Dots\"] = value_list\n",
        "\n",
        "    set_nuclei = set(Droplets_DF[\"Nucleus_ID\"])\n",
        "    Droplets_DF = pd.concat([Droplets_DF, Dots_Nucleus], axis=1)\n",
        "\n",
        "    for n_nucleo in set_nuclei:\n",
        "      Droplets_DF.loc[Droplets_DF.Nucleus_ID == n_nucleo,\"partition ratio\"] = Droplets_DF[\"Fluorescence\"] / float(Nuclei_DF[Nuclei_DF['Nb'] == n_nucleo]['Channel intensisty'])\n",
        "\n",
        "    Droplets_DF.to_excel(xlsx_file, sheet_name = \"analysis\")\n",
        "\n",
        "    xlsx_file.save()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yrQ99dGWBRck",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad515d81-6579-4e67-96e0-c2f034e4f16f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['M_5122_eff_tex_kap_suz12 - Mark_and_Find_001-Pos007_S001.tif.csv',\n",
              " 'Q_5122_eff_tex_kap_suz12 - Mark_and_Find_001-Pos007_S001.tif KAP1.csv',\n",
              " 'Q_5122_eff_tex_kap_suz12 - Mark_and_Find_001-Pos007_S001.tif SUZ12.csv',\n",
              " 'serie_07.csv']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uqNTCscqmZS4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "fd54eab8-ed52-4cfc-eaaf-4e3f4231812a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nfor experiment in directory_analysis:\\n\\n  # Lista dei centroidi dei nuclei\\n  # Tutte le distanze/volumi sono in pixel/voxel, sono da moltiplicare per la dimensione reale\\n  # Nuclei = [(X_centroid, Y_centroid, Z_centroid, X_max, X_min, Y_max, Y_min, Z_max, Z_min, volume)]\\n  #nuclei = [(\"N_nuclei\", \"x_c_nuclei\", \"y_c_nuclei\", \"z_c_nuclei\", \"volume_nuclei\", \"X_max\", \"X_min\", \"Y_max\", \"Y_min\", \"Z_max\", \"Z_min\")]\\n\\n  csv = os.listdir(experiment)\\n  file_path = experiment + \"/\" + csv[1]\\n  csv.sort()\\n  print(experiment)\\n  xlsx_file_path = experiment + \"/\" + experiment.split(\"/\")[-1] + \".xlsx\"\\n  print(xlsx_file_path)\\n  xlsx_file = pd.ExcelWriter(xlsx_file_path, engine=\\'xlsxwriter\\')\\n\\n  print(csv)\\n\\n  nome_file_nuclei = experiment + \"/\" + csv[1]\\n  nome_file_droplet = experiment + \"/\" + csv[0]\\n  nome_file_quantifiche_nucleo_canale = experiment + \"/\" + csv[3]\\n\\n  nuclei_data = []\\n\\n  N_nuclei = pd.read_csv(nome_file_nuclei)[\\'Nb\\'].tolist()\\n  x_c_nuclei = pd.read_csv(nome_file_nuclei)[\\'CX (unit)\\'].tolist()\\n  y_c_nuclei = pd.read_csv(nome_file_nuclei)[\\'CY (unit)\\'].tolist()\\n  z_c_nuclei = pd.read_csv(nome_file_nuclei)[\\'CZ (unit)\\'].tolist()\\n  volume_nuclei = pd.read_csv(nome_file_nuclei)[\\'Vol (unit)\\'].tolist()\\n\\n  N_nuclei_canale = pd.read_csv(nome_file_quantifiche_nucleo_canale)[\\'Nb\\'].tolist()\\n  MFI = pd.read_csv(nome_file_quantifiche_nucleo_canale)[\\'Mean\\'].tolist()\\n\\n  channel_data = [(N_nuclei_canale[i], MFI[i]) for i in range(0, len(x_c_nuclei))]\\n\\n  #X_max = pd.read_csv(nome_file_nuclei)[\\'Xmax (pix)\\'].tolist()\\n  #X_min = pd.read_csv(nome_file_nuclei)[\\'Xmin (pix)\\'].tolist()\\n  #Y_max = pd.read_csv(nome_file_nuclei)[\\'Ymax (pix)\\'].tolist()\\n  #Y_min = pd.read_csv(nome_file_nuclei)[\\'Ymin (pix)\\'].tolist()\\n  #Z_max = pd.read_csv(nome_file_nuclei)[\\'Zmax (pix)\\'].tolist()\\n  #Z_min = pd.read_csv(nome_file_nuclei)[\\'Zmin (pix)\\'].tolist()\\n\\n  #nuclei_data = [(N_nuclei[i], x_c_nuclei[i], y_c_nuclei[i], z_c_nuclei[i], volume_nuclei[i], X_max[i], X_min[i], Y_max[i], Y_min[i], Z_max[i], Z_min[i]) for i in range(0, len(x_c_nuclei))]\\n  nuclei_data = [(N_nuclei[i], x_c_nuclei[i], y_c_nuclei[i], z_c_nuclei[i], volume_nuclei[i]) for i in range(0, len(x_c_nuclei))]\\n\\n  # Droplet = [(x_c_droplet, y_c_droplet, z_c_droplet, droplet_fluorescence droplet_volume, nucleo associato, x del nucleo, y del nucleo, distanza dal centroide)]\\n\\n  x_c_droplet_pix = pd.read_csv(nome_file_droplet)[\\'X\\'].tolist()\\n  x_c_droplet = [i * x_pixel for i in x_c_droplet_pix]\\n  y_c_droplet_pix = pd.read_csv(nome_file_droplet)[\\'Y\\'].tolist()\\n  y_c_droplet = [i * x_pixel for i in y_c_droplet_pix]\\n  z_c_droplet_pix = pd.read_csv(nome_file_droplet)[\\'Z\\'].tolist()\\n  z_c_droplet = [i * z_pixel for i in z_c_droplet_pix]\\n  droplet_volume_vox = pd.read_csv(nome_file_droplet)[\\'Size\\'].tolist()\\n  droplet_volume = [i * voxel_size for i in droplet_volume_vox]\\n  droplet_fluorescence = pd.read_csv(nome_file_droplet)[\\'Av\\'].tolist()\\n\\n  #le_aree = pd.read_csv(nome_file_droplet + \\'.csv\\')[\\'Size\\'].tolist()\\n  #le_fluorescenze = pd.read_csv(nome_file_droplet + \\'.csv\\')[\\'Av\\'].tolist()\\n  droplets = [[x_c_droplet[i], y_c_droplet[i], z_c_droplet[i], droplet_volume[i], droplet_fluorescence[i], 0, 0, 0, 0, 0, None, None, 0] for i in range(0, len(x_c_droplet))]\\n  droplets_list = [[x_c_droplet[i], y_c_droplet[i], z_c_droplet[i], droplet_volume[i], droplet_fluorescence[i], 0, 0, 0, 0, 0, None, None, 0] for i in range(0, len(x_c_droplet))]\\n\\n  Nuclei_DF = pd.DataFrame (nuclei_data, columns = [\"Nb\", \"Cx\", \"Cy\",\"Cz\",\"Volume_unit\"])\\n  Nuclei_DF[\"Nb\"] = Nuclei_DF[\"Nb\"] + 1\\n  Nuclei_DF[\\'Channel intensisty\\'] = pd.read_csv(nome_file_quantifiche_nucleo_canale)[\\'Mean\\'].tolist()\\n  Nuclei_DF.drop(Nuclei_DF[Nuclei_DF[\\'Volume_unit\\'] <= 10].index, inplace = True)\\n  Nuclei_DF[\"Volume_pix\"] = Nuclei_DF[\"Volume_unit\"] / voxel_size\\n\\n  Droplets_DF = pd.DataFrame (droplets_list, columns = [\"Cx\",\"Cy\",\"Cz\",\"Volume_unit\",\"Fluorescence\",\"Centroid_distance\",\"Nucleus_ID\",\"0\",\"0\",\"0\",\"Nucleo\",\"N_Dots\",\"0\"])\\n\\n  conta_dxn = {}\\n  nuclei_index = []\\n  min_distance = []\\n  Nuclei_index_touse = Nuclei_DF.Nb.tolist()\\n  for i, row_D in Droplets_DF.iterrows():\\n    distances = []\\n    for k, row_N in Nuclei_DF.iterrows():\\n      droplet_distance = distance_3D (row_D,row_N)\\n      distances.append(droplet_distance)\\n    index_min = distances.index(min(distances))\\n    min_distance.append(min(distances))\\n    nuclei_index.append(Nuclei_index_touse[index_min])\\n\\n  Droplets_DF[\"Centroid_distance\"] = min_distance\\n  Droplets_DF[\"Nucleus_ID\"] = nuclei_index\\n  Droplets_DF[\"Nucleus_ID\"] = Droplets_DF[\"Nucleus_ID\"]\\n  Droplets_DF.drop(Droplets_DF[Droplets_DF[\\'Centroid_distance\\'] >= 20].index, inplace = True)\\n\\n  conta_dxn = Counter(Droplets_DF[\"Nucleus_ID\"])\\n  keys = list(conta_dxn.keys())\\n  keys.sort()\\n  sorted_conta_dxn = {i: conta_dxn[i] for i in keys}\\n\\n  key_list = list(sorted_conta_dxn.keys())\\n  value_list = list(sorted_conta_dxn.values())\\n  Dots_Nucleus = pd.DataFrame(key_list, columns = [\"Nucleo\"])\\n  Dots_Nucleus[\"Dots\"] = value_list\\n\\n  set_nuclei = set(Droplets_DF[\"Nucleus_ID\"])\\n  Droplets_DF = pd.concat([Droplets_DF, Dots_Nucleus], axis=1)\\n\\n  for n_nucleo in set_nuclei:\\n\\n    Droplets_DF[\"Volume_pix\"] = Droplets_DF[\"Volume_unit\"] / voxel_size\\n    sum_droplet_volume = Droplets_DF[Droplets_DF[\"Nucleus_ID\"] == n_nucleo][\"Volume_pix\"].sum()\\n    Droplets_DF[\\'Total_intensity\\'] = Droplets_DF[\"Volume_pix\"] * Droplets_DF[\"Fluorescence\"]\\n    sum_droplet_fluo = Droplets_DF[Droplets_DF[\"Nucleus_ID\"] == n_nucleo][\\'Total_intensity\\'].sum()\\n    Nuclei_DF[\\'Total intensity\\'] = Nuclei_DF[\\'Volume_pix\\'] * Nuclei_DF[\\'Channel intensisty\\']\\n    background_int_total = Nuclei_DF[Nuclei_DF[\\'Nb\\'] == n_nucleo][\\'Total intensity\\'] - sum_droplet_fluo\\n    Nuclei_DF.loc[Nuclei_DF.Nb == n_nucleo, \"Background_intensity_total\"] = background_int_total\\n    background_volume_pix = Nuclei_DF[Nuclei_DF[\"Nb\"] == n_nucleo][\"Volume_pix\"] - sum_droplet_volume\\n    Nuclei_DF.loc[Nuclei_DF.Nb == n_nucleo, \"Background_volume_pix\"] = background_volume_pix\\n    #Nuclei_DF.drop(Nuclei_DF[Nuclei_DF[\\'Background_intensity_total\\'] <= 0].index, inplace = True)\\n    Nuclei_DF[\"Background_MFI\"] = Nuclei_DF[\"Background_intensity_total\"] / Nuclei_DF [\"Background_volume_pix\"]\\n    MFI_bcg = Nuclei_DF[Nuclei_DF[\\'Nb\\'] == n_nucleo][\\'Background_MFI\\']\\n\\n    Droplets_DF.loc[Droplets_DF.Nucleus_ID == n_nucleo,\"partition ratio\"] = Droplets_DF[\"Fluorescence\"] / float(Nuclei_DF[Nuclei_DF[\\'Nb\\'] == n_nucleo][\\'Background_MFI\\'])\\n\\n  Droplets_DF.to_excel(xlsx_file, sheet_name = \"analysis\")\\n  xlsx_file.save()\\n  '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "\"\"\"\n",
        "for experiment in directory_analysis:\n",
        "\n",
        "  # Lista dei centroidi dei nuclei\n",
        "  # Tutte le distanze/volumi sono in pixel/voxel, sono da moltiplicare per la dimensione reale\n",
        "  # Nuclei = [(X_centroid, Y_centroid, Z_centroid, X_max, X_min, Y_max, Y_min, Z_max, Z_min, volume)]\n",
        "  #nuclei = [(\"N_nuclei\", \"x_c_nuclei\", \"y_c_nuclei\", \"z_c_nuclei\", \"volume_nuclei\", \"X_max\", \"X_min\", \"Y_max\", \"Y_min\", \"Z_max\", \"Z_min\")]\n",
        "\n",
        "  csv = os.listdir(experiment)\n",
        "  file_path = experiment + \"/\" + csv[1]\n",
        "  csv.sort()\n",
        "  print(experiment)\n",
        "  xlsx_file_path = experiment + \"/\" + experiment.split(\"/\")[-1] + \".xlsx\"\n",
        "  print(xlsx_file_path)\n",
        "  xlsx_file = pd.ExcelWriter(xlsx_file_path, engine='xlsxwriter')\n",
        "\n",
        "  print(csv)\n",
        "\n",
        "  nome_file_nuclei = experiment + \"/\" + csv[1]\n",
        "  nome_file_droplet = experiment + \"/\" + csv[0]\n",
        "  nome_file_quantifiche_nucleo_canale = experiment + \"/\" + csv[3]\n",
        "\n",
        "  nuclei_data = []\n",
        "\n",
        "  N_nuclei = pd.read_csv(nome_file_nuclei)['Nb'].tolist()\n",
        "  x_c_nuclei = pd.read_csv(nome_file_nuclei)['CX (unit)'].tolist()\n",
        "  y_c_nuclei = pd.read_csv(nome_file_nuclei)['CY (unit)'].tolist()\n",
        "  z_c_nuclei = pd.read_csv(nome_file_nuclei)['CZ (unit)'].tolist()\n",
        "  volume_nuclei = pd.read_csv(nome_file_nuclei)['Vol (unit)'].tolist()\n",
        "\n",
        "  N_nuclei_canale = pd.read_csv(nome_file_quantifiche_nucleo_canale)['Nb'].tolist()\n",
        "  MFI = pd.read_csv(nome_file_quantifiche_nucleo_canale)['Mean'].tolist()\n",
        "\n",
        "  channel_data = [(N_nuclei_canale[i], MFI[i]) for i in range(0, len(x_c_nuclei))]\n",
        "\n",
        "  #X_max = pd.read_csv(nome_file_nuclei)['Xmax (pix)'].tolist()\n",
        "  #X_min = pd.read_csv(nome_file_nuclei)['Xmin (pix)'].tolist()\n",
        "  #Y_max = pd.read_csv(nome_file_nuclei)['Ymax (pix)'].tolist()\n",
        "  #Y_min = pd.read_csv(nome_file_nuclei)['Ymin (pix)'].tolist()\n",
        "  #Z_max = pd.read_csv(nome_file_nuclei)['Zmax (pix)'].tolist()\n",
        "  #Z_min = pd.read_csv(nome_file_nuclei)['Zmin (pix)'].tolist()\n",
        "\n",
        "  #nuclei_data = [(N_nuclei[i], x_c_nuclei[i], y_c_nuclei[i], z_c_nuclei[i], volume_nuclei[i], X_max[i], X_min[i], Y_max[i], Y_min[i], Z_max[i], Z_min[i]) for i in range(0, len(x_c_nuclei))]\n",
        "  nuclei_data = [(N_nuclei[i], x_c_nuclei[i], y_c_nuclei[i], z_c_nuclei[i], volume_nuclei[i]) for i in range(0, len(x_c_nuclei))]\n",
        "\n",
        "  # Droplet = [(x_c_droplet, y_c_droplet, z_c_droplet, droplet_fluorescence droplet_volume, nucleo associato, x del nucleo, y del nucleo, distanza dal centroide)]\n",
        "\n",
        "  x_c_droplet_pix = pd.read_csv(nome_file_droplet)['X'].tolist()\n",
        "  x_c_droplet = [i * x_pixel for i in x_c_droplet_pix]\n",
        "  y_c_droplet_pix = pd.read_csv(nome_file_droplet)['Y'].tolist()\n",
        "  y_c_droplet = [i * x_pixel for i in y_c_droplet_pix]\n",
        "  z_c_droplet_pix = pd.read_csv(nome_file_droplet)['Z'].tolist()\n",
        "  z_c_droplet = [i * z_pixel for i in z_c_droplet_pix]\n",
        "  droplet_volume_vox = pd.read_csv(nome_file_droplet)['Size'].tolist()\n",
        "  droplet_volume = [i * voxel_size for i in droplet_volume_vox]\n",
        "  droplet_fluorescence = pd.read_csv(nome_file_droplet)['Av'].tolist()\n",
        "\n",
        "  #le_aree = pd.read_csv(nome_file_droplet + '.csv')['Size'].tolist()\n",
        "  #le_fluorescenze = pd.read_csv(nome_file_droplet + '.csv')['Av'].tolist()\n",
        "  droplets = [[x_c_droplet[i], y_c_droplet[i], z_c_droplet[i], droplet_volume[i], droplet_fluorescence[i], 0, 0, 0, 0, 0, None, None, 0] for i in range(0, len(x_c_droplet))]\n",
        "  droplets_list = [[x_c_droplet[i], y_c_droplet[i], z_c_droplet[i], droplet_volume[i], droplet_fluorescence[i], 0, 0, 0, 0, 0, None, None, 0] for i in range(0, len(x_c_droplet))]\n",
        "\n",
        "  Nuclei_DF = pd.DataFrame (nuclei_data, columns = [\"Nb\", \"Cx\", \"Cy\",\"Cz\",\"Volume_unit\"])\n",
        "  Nuclei_DF[\"Nb\"] = Nuclei_DF[\"Nb\"] + 1\n",
        "  Nuclei_DF['Channel intensisty'] = pd.read_csv(nome_file_quantifiche_nucleo_canale)['Mean'].tolist()\n",
        "  Nuclei_DF.drop(Nuclei_DF[Nuclei_DF['Volume_unit'] <= 10].index, inplace = True)\n",
        "  Nuclei_DF[\"Volume_pix\"] = Nuclei_DF[\"Volume_unit\"] / voxel_size\n",
        "\n",
        "  Droplets_DF = pd.DataFrame (droplets_list, columns = [\"Cx\",\"Cy\",\"Cz\",\"Volume_unit\",\"Fluorescence\",\"Centroid_distance\",\"Nucleus_ID\",\"0\",\"0\",\"0\",\"Nucleo\",\"N_Dots\",\"0\"])\n",
        "\n",
        "  conta_dxn = {}\n",
        "  nuclei_index = []\n",
        "  min_distance = []\n",
        "  Nuclei_index_touse = Nuclei_DF.Nb.tolist()\n",
        "  for i, row_D in Droplets_DF.iterrows():\n",
        "    distances = []\n",
        "    for k, row_N in Nuclei_DF.iterrows():\n",
        "      droplet_distance = distance_3D (row_D,row_N)\n",
        "      distances.append(droplet_distance)\n",
        "    index_min = distances.index(min(distances))\n",
        "    min_distance.append(min(distances))\n",
        "    nuclei_index.append(Nuclei_index_touse[index_min])\n",
        "\n",
        "  Droplets_DF[\"Centroid_distance\"] = min_distance\n",
        "  Droplets_DF[\"Nucleus_ID\"] = nuclei_index\n",
        "  Droplets_DF[\"Nucleus_ID\"] = Droplets_DF[\"Nucleus_ID\"]\n",
        "  Droplets_DF.drop(Droplets_DF[Droplets_DF['Centroid_distance'] >= 20].index, inplace = True)\n",
        "\n",
        "  conta_dxn = Counter(Droplets_DF[\"Nucleus_ID\"])\n",
        "  keys = list(conta_dxn.keys())\n",
        "  keys.sort()\n",
        "  sorted_conta_dxn = {i: conta_dxn[i] for i in keys}\n",
        "\n",
        "  key_list = list(sorted_conta_dxn.keys())\n",
        "  value_list = list(sorted_conta_dxn.values())\n",
        "  Dots_Nucleus = pd.DataFrame(key_list, columns = [\"Nucleo\"])\n",
        "  Dots_Nucleus[\"Dots\"] = value_list\n",
        "\n",
        "  set_nuclei = set(Droplets_DF[\"Nucleus_ID\"])\n",
        "  Droplets_DF = pd.concat([Droplets_DF, Dots_Nucleus], axis=1)\n",
        "\n",
        "  for n_nucleo in set_nuclei:\n",
        "\n",
        "    Droplets_DF[\"Volume_pix\"] = Droplets_DF[\"Volume_unit\"] / voxel_size\n",
        "    sum_droplet_volume = Droplets_DF[Droplets_DF[\"Nucleus_ID\"] == n_nucleo][\"Volume_pix\"].sum()\n",
        "    Droplets_DF['Total_intensity'] = Droplets_DF[\"Volume_pix\"] * Droplets_DF[\"Fluorescence\"]\n",
        "    sum_droplet_fluo = Droplets_DF[Droplets_DF[\"Nucleus_ID\"] == n_nucleo]['Total_intensity'].sum()\n",
        "    Nuclei_DF['Total intensity'] = Nuclei_DF['Volume_pix'] * Nuclei_DF['Channel intensisty']\n",
        "    background_int_total = Nuclei_DF[Nuclei_DF['Nb'] == n_nucleo]['Total intensity'] - sum_droplet_fluo\n",
        "    Nuclei_DF.loc[Nuclei_DF.Nb == n_nucleo, \"Background_intensity_total\"] = background_int_total\n",
        "    background_volume_pix = Nuclei_DF[Nuclei_DF[\"Nb\"] == n_nucleo][\"Volume_pix\"] - sum_droplet_volume\n",
        "    Nuclei_DF.loc[Nuclei_DF.Nb == n_nucleo, \"Background_volume_pix\"] = background_volume_pix\n",
        "    #Nuclei_DF.drop(Nuclei_DF[Nuclei_DF['Background_intensity_total'] <= 0].index, inplace = True)\n",
        "    Nuclei_DF[\"Background_MFI\"] = Nuclei_DF[\"Background_intensity_total\"] / Nuclei_DF [\"Background_volume_pix\"]\n",
        "    MFI_bcg = Nuclei_DF[Nuclei_DF['Nb'] == n_nucleo]['Background_MFI']\n",
        "\n",
        "    Droplets_DF.loc[Droplets_DF.Nucleus_ID == n_nucleo,\"partition ratio\"] = Droplets_DF[\"Fluorescence\"] / float(Nuclei_DF[Nuclei_DF['Nb'] == n_nucleo]['Background_MFI'])\n",
        "\n",
        "  Droplets_DF.to_excel(xlsx_file, sheet_name = \"analysis\")\n",
        "  xlsx_file.save()\n",
        "  \"\"\"\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}